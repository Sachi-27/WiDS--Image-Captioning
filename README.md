# Project Overview
The focus of this project is on developing a machine learning model for Image Captioning. The project was carried out in 5 weeks, with each week dedicated to learning and implementing specific techniques and algorithms.

## Week 1
- Focus on gaining a strong foundation in libraries such as Numpy, Pandas and Matplotlib for data analysis, manipulation, and visualization.
- Introduction to Machine Learning Tools and basic concepts, including predicting the quality of products based on its features.
- Exploration of ML algorithms like XGBoost and Regressors, with an emphasis on handling skewed data.

## Week 2
- Study of handwritten digit recognition using Feed forward neural networks on the MNIST dataset.
- Preprocessing of images, including concepts like Backpropagation.

## Week 3
- Basic Image Captioning using a CNN model, with an emphasis on object detection and classification.
- Study of Image Net winner models such as ResNet, VGGNet, AlexNet, etc.

## Week 4
- Focus on RNN, starting with the use of LSTMs for Oil Price predictions.
- Study of LSTM functionality, with a focus on NLP techniques like tokenization, lemmatization, and feature vectorization.
- Sentiment Analysis project, with a comparison of various vectorizer methods (TFIDF, Bag of words) and ML models (CNN, FNN) to find the best combination.

## Week 5
- Final project proposal of a merging-based encoder-decoder architecture that incorporates CNN for image feature extraction and RNN for text processing.
- Use of transfer learning with the pretrained VGG19 model as the feature encoder.
- Text encoder processes the tokenized words, while the decoder takes the concatenated outputs from both encoders.
- Minimal repetition in generated captions ensured.
